{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "# Mohit Bhasin\n# HW4 Q4\n# Beer Reviews\n# These data contain 2,924,163 reviews by 40,213 unique users on 110,419 unique types of beer.\n\n# J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013.", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 31, "cell_type": "code", "source": "from pyspark.mllib.feature import HashingTF, IDF, Normalizer\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree, RandomForest, GradientBoostedTrees\nimport re", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 33, "cell_type": "code", "source": "import json\nall_reviews = sc.textFile(\"s3n://stat-37601/ratings.json\", minPartitions=1000).map(json.loads)\nreviews, reviews_test = all_reviews.randomSplit([.01, .99])\nreviews.cache\nreviews.count()", "outputs": [{"execution_count": 33, "output_type": "execute_result", "data": {"text/plain": "29376"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 25, "cell_type": "code", "source": "# Let's see what a review looks like\nreviews.take(1)[0]", "outputs": [{"execution_count": 25, "output_type": "execute_result", "data": {"text/plain": "{u'beer_ABV': u'6.4',\n u'beer_beerId': u'19539',\n u'beer_brewerId': u'2495',\n u'beer_name': u'Erebuni',\n u'beer_style': u'Strong Pale Lager/Imperial Pils',\n u'review_appearance': u'4/5',\n u'review_aroma': u'5/10',\n u'review_overall': u'11/20',\n u'review_palate': u'3/5',\n u'review_profileName': u'JPDIPSO',\n u'review_taste': u'5/10',\n u'review_text': u'Strong grassy hops abound and are detected from a great distance. Hints of dry pale and caramel malt. As the hops fade, there seems to very little left. Golden liquid with a moderate off-white head and nice lace.  Solid, yet, somewhat grain malt in the front that give way to a herbal grassy bitterness in the middle. Finishes slightly crisp, but there is a touch of metal/mineral that distracts in the linger. Certainly not one of the worst euro strongs out there.',\n u'review_time': u'1188950400'}"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 34, "cell_type": "code", "source": "def getLabel(review):\n    \"\"\"\n    Get the overall rating from a review\n    \"\"\"\n    label, total = review[\"review_overall\"].split(\"/\")\n    return float(label) / float(total)\nlabels = reviews.map(getLabel)", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##### Map ['review text'] to a vocabaulary of words with word counts", "cell_type": "markdown", "metadata": {}}, {"execution_count": 35, "cell_type": "code", "source": "# Using a simple parser - make text lowercase, remove punctuation and split on blank space\n# Then count the occurences of each word\ndef removePunctuation(text):\n    \"\"\"\n    Replaces anything that is not a lowercase letter, a space, or an apostrophe with a space:\n    \"\"\"\n    stripped = re.sub('[^a-z\\ \\']+', \" \", text)\n    return stripped\n\nword_counts = reviews.map(lambda x: x[\"review_text\"].lower()).map(removePunctuation).flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a,b: a + b)\nprint(word_counts.take(10)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(u'jblauvs', 1), (u'flavouor', 1), (u'bourdon', 1), (u'opera', 1), (u'nun', 5), (u'inintressante', 1), (u'montreals', 1), (u'wasent', 1), (u'istllet', 2), (u'stopping', 4)]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##### See what words show up often so that we can filter to the words we want", "cell_type": "markdown", "metadata": {}}, {"execution_count": 36, "cell_type": "code", "source": "count_words = word_counts.map(lambda (a,b): (b,a)).sortByKey(False)\nwordcount = count_words.count()", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 37, "cell_type": "code", "source": "wordcount", "outputs": [{"execution_count": 37, "output_type": "execute_result", "data": {"text/plain": "32589"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 38, "cell_type": "code", "source": "percent_words =  count_words.map(lambda (a,b): (round(float(a)/wordcount,2),b))\nprint(percent_words.take(10)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(2.09, u'a'), (1.71, u'and'), (1.48, u'the'), (1.27, u'with'), (1.12, u'of'), (0.92, u'is'), (0.63, u'head'), (0.54, u'aroma'), (0.51, u'to'), (0.45, u'in')]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "We can see that the \"stop words\" are words that occur >~85% of the time. We filter these words out.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 39, "cell_type": "code", "source": "percent_words_small = percent_words.filter(lambda (k,v): k<.85 and k>.001)\nprint(percent_words_small.take(5)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(0.63, u'head'), (0.54, u'aroma'), (0.51, u'to'), (0.45, u'in'), (0.45, u'this')]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 49, "cell_type": "code", "source": "wordlist = percent_words_small.map(lambda (k,v): v).collect()\nn_features = len(wordlist)\nprint(n_features)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "845\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##### We now have a list of words (230 words) that we need to compute our TF-IDF on", "cell_type": "markdown", "metadata": {}}, {"execution_count": 59, "cell_type": "code", "source": "def reviewParser(review_text):\n    \"\"\"\n    Filter the review text to only words that show up in the vocabulary we built above \n    \"\"\"\n    words = review_text.lower()\n    words = re.sub('[^a-z\\ \\']+', \" \", words).split()\n    words = [word for word in words if word in wordlist]\n    return (words)\n\nfiltered_reviews = reviews.map(lambda x: x['review_text']).map(reviewParser)", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##### The term frequency function below creates a sparse vector of frequency counts for each word in a given review . The hash is a Spark function that does this more efficiently. Notice that the length of the sparse vector is less than the length of our wordlist, this is aresult of the hashing.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 60, "cell_type": "code", "source": "hashingTF = HashingTF(n_features)\ntf = hashingTF.transform(filtered_reviews)\ntf.take(1)", "outputs": [{"execution_count": 60, "output_type": "execute_result", "data": {"text/plain": "[SparseVector(845, {15: 1.0, 88: 1.0, 116: 1.0, 239: 1.0, 246: 1.0, 338: 1.0, 364: 1.0, 379: 1.0, 381: 1.0, 427: 1.0, 430: 1.0, 449: 1.0, 450: 1.0, 475: 1.0, 547: 1.0, 573: 1.0, 578: 1.0, 675: 1.0, 676: 1.0, 712: 1.0, 723: 1.0, 754: 1.0, 762: 1.0, 820: 1.0, 828: 1.0}),\n SparseVector(845, {8: 1.0, 65: 1.0, 86: 1.0, 230: 4.0, 244: 1.0, 269: 2.0, 277: 2.0, 305: 1.0, 307: 2.0, 396: 1.0, 422: 1.0, 430: 1.0, 444: 1.0, 470: 3.0, 475: 2.0, 489: 1.0, 554: 3.0, 573: 1.0, 576: 1.0, 578: 2.0, 602: 1.0, 642: 3.0, 676: 2.0, 685: 1.0, 694: 2.0, 789: 2.0, 835: 2.0})]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 61, "cell_type": "code", "source": "tf.cache()\nidf = IDF(minDocFreq=2).fit(tf)\nfeatures = idf.transform(tf)\nfeatures.take(1)", "outputs": [{"execution_count": 61, "output_type": "execute_result", "data": {"text/plain": "[SparseVector(845, {15: 1.7704, 88: 1.8539, 116: 2.3001, 239: 1.3149, 246: 4.0341, 338: 1.6621, 364: 2.2524, 379: 1.2307, 381: 2.2059, 427: 0.9955, 430: 1.5026, 449: 2.5131, 450: 2.1482, 475: 0.3765, 547: 1.1584, 573: 1.1663, 578: 0.5884, 675: 3.8994, 676: 1.3091, 712: 2.8632, 723: 1.0717, 754: 2.6435, 762: 2.3449, 820: 1.4662, 828: 3.4045}),\n SparseVector(845, {8: 1.8187, 65: 4.1225, 86: 2.7108, 230: 6.1245, 244: 1.1272, 269: 2.6166, 277: 2.7833, 305: 1.0882, 307: 6.4601, 396: 2.3158, 422: 2.6092, 430: 1.5026, 444: 2.3322, 470: 3.4889, 475: 0.7529, 489: 2.9108, 554: 4.0597, 573: 1.1663, 576: 4.4415, 578: 1.1769, 602: 1.6842, 642: 4.8026, 676: 2.6181, 685: 2.9241, 694: 2.8388, 789: 1.9759, 835: 5.0279})]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 62, "cell_type": "code", "source": "data = features.zip(labels).map(lambda (feature, label): LabeledPoint(label, feature))", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": null, "cell_type": "code", "source": "def meanSquaredError(lAndP):\n    \"\"\"\n    Calculate squared Errror \n    \"\"\"\n    mse_err = lAndP.map(lambda (v,p): (v-p)**2).reduce(lambda a,b: a+b)/float(lAndP.count())\n    return (mse_err)", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"source": "## Decision Trees\nBuild a decision tree on the (x,y) data designed above. Use that to make predictions and take a look at those predictions.\nFinally compute the mean squared error based on the predictions", "cell_type": "markdown", "metadata": {}}, {"execution_count": 63, "cell_type": "code", "source": "model = DecisionTree.trainRegressor(data, categoricalFeaturesInfo={},\n                                    impurity='variance', maxDepth=2, maxBins=2)\npredictions = model.predict(data.map(lambda x: x.features)) # Predict on in-sample\nlabelsAndPredictions = data.map(lambda lp: lp.label).zip(predictions) ", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 65, "cell_type": "code", "source": "labelsAndPredictions.take(5)", "outputs": [{"execution_count": 65, "output_type": "execute_result", "data": {"text/plain": "[(0.65, 0.6861130374479889),\n (0.75, 0.6164411725693068),\n (0.4, 0.6164411725693068),\n (0.7, 0.7398477157360409),\n (0.45, 0.6164411725693068)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "### Calculate the mean squared error of our predictions", "cell_type": "markdown", "metadata": {}}, {"execution_count": 66, "cell_type": "code", "source": "meanSquaredError(labelsAndPredictions)\n", "outputs": [{"execution_count": 66, "output_type": "execute_result", "data": {"text/plain": "0.02553340558226822"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "## Random Forests", "cell_type": "markdown", "metadata": {}}, {"execution_count": 67, "cell_type": "code", "source": "model_rf = RandomForest.trainRegressor(data, {}, 2, impurity='variance', maxDepth=2, maxBins=2, seed=42)\npredictions_rf = model_rf.predict(data.map(lambda x: x.features)) # Predict on in-sample\nlabelsAndPredictions_rf = data.map(lambda lp: lp.label).zip(predictions_rf) ", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 68, "cell_type": "code", "source": "labelsAndPredictions_rf.take(5)", "outputs": [{"execution_count": 68, "output_type": "execute_result", "data": {"text/plain": "[(0.65, 0.6281735032893854),\n (0.75, 0.6281735032893854),\n (0.4, 0.6281735032893854),\n (0.7, 0.7257670974132193),\n (0.45, 0.6723545769158192)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 70, "cell_type": "code", "source": "meanSquaredError(labelsAndPredictions_rf)", "outputs": [{"execution_count": 70, "output_type": "execute_result", "data": {"text/plain": "0.025505651267428674"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"source": "Questions\nQ:Why do we need a normalizer?\nQ: Do we need to specify the sparsevector length?\nThats specifies my feature vector length (generally smaller than my vocab because of hashing)\nQ:minDocFreq?\nQ: Ensemble?\n\n5/21\nQ: what does cache do?\nQ: what does max Bins do?\nQ: What is the CV shortcut that was mentioned?\n\nConsider keeping 1K+ words\nNever create a new idf, (i.e same tf, same idf)\nx is 1663 length vector of tfidf values per review\ny is review rating", "cell_type": "markdown", "metadata": {}}, {"execution_count": 29, "cell_type": "code", "source": "# Appendix\n\ndef squaredError(preds):\n    \"\"\"\n    Calculate squared Errror \n    \"\"\"\n    sse = (preds[1]-preds[0])^2\n    return (preds[1]-preds[0])\n\n\n\ndef parser(review_text):\n    \"\"\"\n    Generate feature vector of words from Beer review \n    \"\"\"\n    words = review_text.lower().split()\n    .map(lambda word: (word, 1)) \n             .reduceByKey(lambda a, b: a + b)\n    return (words)", "outputs": [{"execution_count": 29, "output_type": "execute_result", "data": {"text/plain": "1072312"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}