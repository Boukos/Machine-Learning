{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "# Mohit Bhasin\n# HW4 Q4\n# Beer Reviews\n# These data contain 2,924,163 reviews by 40,213 unique users on 110,419 unique types of beer.\n\n# J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013.", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 1, "cell_type": "code", "source": "from pyspark.mllib.feature import HashingTF, IDF, Normalizer\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree, RandomForest, GradientBoostedTrees\nimport re\nimport json", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 2, "cell_type": "code", "source": "all_reviews = sc.textFile(\"s3n://stat-37601/ratings.json\", minPartitions=1000).map(json.loads)\nreviews, reviews_test = all_reviews.randomSplit([.01, .4]) # working on only 50% of the data\nreviews.cache\nreviews.count()", "outputs": [{"execution_count": 2, "output_type": "execute_result", "data": {"text/plain": "71182"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 4, "cell_type": "code", "source": "# Let's see what a review looks like\nreviews.take(1)[0]", "outputs": [{"execution_count": 4, "output_type": "execute_result", "data": {"text/plain": "{u'beer_ABV': u'5.4',\n u'beer_beerId': u'63836',\n u'beer_brewerId': u'8481',\n u'beer_name': u'John Harvards Simcoe IPA',\n u'beer_style': u'India Pale Ale &#40;IPA&#41;',\n u'review_appearance': u'4/5',\n u'review_aroma': u'6/10',\n u'review_overall': u'13/20',\n u'review_palate': u'3/5',\n u'review_profileName': u'hopdog',\n u'review_taste': u'6/10',\n u'review_text': u'On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.',\n u'review_time': u'1157587200'}"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##Building a text parser\nMake text lowercase, remove punctuation and split on blank spaces.\nThen count the occurences of each word.\nFinally see what words show up often so that we can filter to the words we want.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "def removePunctuation(text):\n    \"\"\"\n    Replaces anything that is not a lowercase letter, a space, or an apostrophe with a space:\n    \"\"\"\n    stripped = re.sub('[^a-z\\ \\']+', \" \", text)\n    return stripped\n\nword_counts = reviews.map(lambda x: x[\"review_text\"].lower()).map(removePunctuation).flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a,b: a + b)\nprint(word_counts.take(10)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(u'oraneg', 2), (u'promoted', 3), (u'bifrost', 1), (u'hadent', 1), (u'dba', 2), (u'matbe', 1), (u'marti', 1), (u'nun', 8), (u'buccal', 1), (u'appelwine', 2)]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 4, "cell_type": "code", "source": "count_words = word_counts.map(lambda (a,b): (b,a)).sortByKey(False)\nwordcount = count_words.count()\nwordcount", "outputs": [{"execution_count": 4, "output_type": "execute_result", "data": {"text/plain": "51611"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 5, "cell_type": "code", "source": "percent_words =  count_words.map(lambda (a,b): (round(float(a)/wordcount,2),b))\nprint(percent_words.take(10)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(3.22, u'a'), (2.65, u'and'), (2.32, u'the'), (1.95, u'with'), (1.72, u'of'), (1.42, u'is'), (0.97, u'head'), (0.83, u'aroma'), (0.79, u'to'), (0.7, u'in')]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "We can see that the \"stop words\" are words that occur frequently. We filter these words out. Our final word list comprises our feature vector that we need to compute our TF-IDF on", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "percent_words_small = percent_words.filter(lambda (k,v): k<.85 and k>.001)\nprint(percent_words_small.take(5)),", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(0.83, u'aroma'), (0.79, u'to'), (0.7, u'in'), (0.69, u'this'), (0.65, u'but')]\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 7, "cell_type": "code", "source": "wordlist = percent_words_small.map(lambda (k,v): v).collect()\nn_features = len(wordlist)\nprint(n_features)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1162\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 8, "cell_type": "code", "source": "def reviewParser(review_text):\n    \"\"\"\n    Filter the review text to only words that show up in the vocabulary we built above \n    \"\"\"\n    words = review_text.lower()\n    words = re.sub('[^a-z\\ \\']+', \" \", words).split()\n    words = [word for word in words if word in wordlist]\n    return (words)\n\nfiltered_reviews = reviews.map(lambda x: x['review_text']).map(reviewParser)", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"source": "##TF-IDF\nTF-IDF is better than using simple word frequency counts as our \"X\" predictors\nThe term frequency function below creates a sparse vector of frequency counts for each word in a given review . The hash is a Spark function that does this more efficiently, for tactibility we hash down to a smaller feature vector size (large number of collisions). Notice that the length of the sparse vector is less than the length of our wordlist, this is aresult of the hashing.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "hashingTF = HashingTF(20)\ntf = hashingTF.transform(filtered_reviews)\ntf.take(1)", "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "[SparseVector(20, {0: 1.0, 1: 2.0, 2: 2.0, 3: 3.0, 4: 3.0, 5: 5.0, 6: 2.0, 7: 1.0, 9: 1.0, 10: 3.0, 11: 2.0, 12: 1.0, 14: 3.0, 15: 4.0, 16: 4.0, 17: 3.0, 19: 4.0})]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 10, "cell_type": "code", "source": "tf.cache()\nidf = IDF(minDocFreq=2).fit(tf)\nfeatures = idf.transform(tf)\nfeatures.take(1)", "outputs": [{"execution_count": 10, "output_type": "execute_result", "data": {"text/plain": "[SparseVector(20, {0: 0.2485, 1: 1.3804, 2: 0.4383, 3: 0.4973, 4: 0.5758, 5: 1.3373, 6: 0.5718, 7: 0.3155, 9: 0.2277, 10: 1.1553, 11: 0.6072, 12: 0.2026, 14: 0.7342, 15: 1.7154, 16: 0.987, 17: 0.7708, 19: 1.7826})]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 11, "cell_type": "code", "source": "def getLabel(review):\n    \"\"\"\n    Get the overall rating from a review\n    \"\"\"\n    label, total = review[\"review_overall\"].split(\"/\")\n    return float(label) / float(total)\nlabels = reviews.map(getLabel)\ndata = features.zip(labels).map(lambda (feature, label): LabeledPoint(label, feature))", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"source": "Create a function to calculate the Mean squared error for our models", "cell_type": "markdown", "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": "def meanSquaredError(lAndP):\n    \"\"\"\n    Calculate mean squared error \n    \"\"\"\n    mse_err = lAndP.map(lambda (v,p): (v-p)*(v-p)).sum()/float(lAndP.count())\n    #mse_err = lAndP.map(lambda (v,p): (v-p)**2).reduce(lambda a,b: a+b)/float(lAndP.count())\n    return (mse_err)", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"source": "## Decision Trees\nBuild a decision tree on the (x,y) data designed above. Use that to make predictions and take a look at those predictions. Finally compute the mean squared error based on the predictions.\n\n```python\nclassmethod trainRegressor(data, categoricalFeaturesInfo, impurity='variance', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0)\n```\nThe mse below shows that we get a 2.6% In-Sample error rate.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "model = DecisionTree.trainRegressor(data, categoricalFeaturesInfo={},\n                                    impurity='variance', maxDepth=2, maxBins=2)\npredictions = model.predict(data.map(lambda x: x.features)) # Predict on in-sample\nlabelsAndPredictions = data.map(lambda lp: lp.label).zip(predictions) ", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 14, "cell_type": "code", "source": "labelsAndPredictions.take(5)", "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "[(0.8, 0.6738495252008759),\n (0.65, 0.6161767411059191),\n (0.7, 0.711222679759265),\n (0.6, 0.6161767411059191),\n (0.65, 0.711222679759265)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 21, "cell_type": "code", "source": "meanSquaredError(labelsAndPredictions) #0.026535660477238206", "outputs": [{"execution_count": 21, "output_type": "execute_result", "data": {"text/plain": "0.026535660477238206"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "## Random Forests\nRepeat the same steps from above for a Random Forest\n\n```python\nclassmethod trainRegressor(data, categoricalFeaturesInfo, numTrees, featureSubsetStrategy='auto', impurity='variance', maxDepth=4, maxBins=32, seed=None)\n```", "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": "model_rf = RandomForest.trainRegressor(data, {}, 2, impurity='variance', maxDepth=2, maxBins=2, seed=42)\npredictions_rf = model_rf.predict(data.map(lambda x: x.features)) # Predict on in-sample\nlabelsAndPredictions_rf = data.map(lambda lp: lp.label).zip(predictions_rf) ", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 19, "cell_type": "code", "source": "labelsAndPredictions_rf.take(5)", "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "[(0.8, 0.7301089416883975),\n (0.7, 0.7057365798909006),\n (0.75, 0.7057365798909006),\n (0.6, 0.6339424204090021),\n (0.65, 0.6339424204090021)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 20, "cell_type": "code", "source": "meanSquaredError(labelsAndPredictions_rf)", "outputs": [{"execution_count": 20, "output_type": "execute_result", "data": {"text/plain": "0.026358335341867243"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "## Gradient Boosted Trees\nRepeat the same steps from above for GBTs. We want stumps (shallow trees) so we use maxDepth=1\n\n```python \nclassmethod trainRegressor(data, categoricalFeaturesInfo, loss='leastSquaresError', numIterations=100, learningRate=0.1, maxDepth=3)\n```", "cell_type": "markdown", "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "model_gbt = GradientBoostedTrees.trainRegressor(data, {}, loss='leastSquaresError', maxDepth=1)", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 17, "cell_type": "code", "source": "predictions_gbt = model_gbt.predict(data.map(lambda x: x.features)) # Predict on in-sample\nlabelsAndPredictions_gbt = data.map(lambda lp: lp.label).zip(predictions_gbt) ", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 18, "cell_type": "code", "source": "labelsAndPredictions_gbt.take(5)", "outputs": [{"execution_count": 18, "output_type": "execute_result", "data": {"text/plain": "[(0.8, 0.6913117627223787),\n (0.65, 0.6285516026410404),\n (0.7, 0.7150184495414104),\n (0.6, 0.6271736171888832),\n (0.65, 0.6917288086749391)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 19, "cell_type": "code", "source": "meanSquaredError(labelsAndPredictions_gbt)", "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "0.02553981435951626"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "The models above were tested on a small subset of the data with shallow depths for illustrative purposes. It's clear that Gradient Boosted trees have better mean squared error from the answers above.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}